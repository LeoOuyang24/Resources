This document keeps track of all changes as well as considered changes made to the resources as well as why they were made. Consider this a "learning from the past" kind of document. 

11/3/2024:
	Removed OpaquesManager. It just causes issues. For example, I ran into an issue where an opaque fragment was getting rendered over because it had the same z as another fragment but was rendered first so it got overshadowed. Maybe I'll add it again later. Honestly the whole rendering library could be streamlined a bit. It's over built rn for "efficiency" but is probably way slower than a simpler engine.

8/12/2024:
	Sequencer now uses std::function rather than SequenceUnits and Callables. Well, SequenceUnit still exists, but it's just a type def for an std::function. I have long been worried about std::function's overhead issues but honestly, I don't think it's a big deal. Using std::function on the other hand, allows me to just straight up pass lambdas into Sequencers to construct them, which is a nice bit of syntactical sugar. You can do this with templates, but at some point that template has to be brought down into a std::list. The old SequenceUnit and Callable system was basically a wrapper for this. If you then want to also pass in lambdas into the functions directly without using std::function, you'll have a function that looks like this:

template<typename T>
void addUnit(T t)
{

}

This function can literally take anything, so in order for it to not clash with the normal functions that add a SequenceUnit or SequenceUnit shared pointer, you have to give this function a different name. But that messes with setup(...), which is supposed to allow us to add SequenceUnits, SequenceUnit shared pointers, and raw lambdas since you can no longer use function overloads to automatically call the correct addUnit variation.

This is all a very convoluted way of saying, that I think the old SequenceUnit system was a bit overcooked. It maybe was a little more efficient, if that, who knows I didn't actually test it. Why reinvent the wheel for (maybe) marginally more efficiency when std::function makes the code so much more readable?

8/11/2024:
	Coming back from a Godot break, I've changed RenderRequest to no longer consider sprites when ordering in TransManager. This was done as an efficiency concern: by comparing sprites, sprites of the same kind could all be rendered in one go. However, it meant that there was no ordering based on request order. If Sprite A was requested first, then Sprite B, and let's say Sprite A has a higher memory address than Sprite B, Sprite B would be rendered first. Doesn't it make a lot more sense for a sprite that was requested first to be rendered first? There is of course a performance hit but let's be real here, how often have I really needed to render a ton of shit all at once? I think I've been overthinking efficiency at the cost of ease of use. I'm not making a state of the art engine over here. 

2/23/2024:
	BasicRenderPipeline now allows users to specify differing divisors for each vertex attribute. This allows for more flexibility. Basically, data is sorted and put into a RenderPayload which provides a byte array for all data of a certain divisor. These buffers are then sent to the GPU.
	Requests in TransManager have been changed to a singly-linked forward_list which is unsorted until the actual render function is called. All our requests list has to do is add stuff to the end as fast as possible, so a forward_list seemed like the best choice. Then we sort at the end, which should be O(nlogn). Inserting into a red-black tree or multiset is logn, and we have to do it for all n requests, so it should work out to be the same. 
	OpaqueManager is now GONE. The old way of storing opaques had one byte array for each render request, which at the time was just a Sprite and BasicRenderPipeline pair. In a large project, I expect there to be a lot of small byte arrays just lying around. Seems like a waste of memory, and honestly the overhead of maintaining a single sorted list of requests seems worth it for the memory cost. Sorting being a way to group similar sprites and render pipelines together of course. Wait a minute, this is exactly how TransManager works. In fact, the only difference is that TransManager sorts by z as well. So now, OpaqueManager is just another TransManager. SpriteManager pushes requests to OpaqueManager (a TransManager) the same as pushing to the TransManager except each request has a z of 0. There is a bit of a small redudancy here, since each Opaque request will still compare zs. Seems not that important rn though. 

BENCHMARKS: 
Rendering 100000 10x10 sprites of benchmark_test.png in a 640x640 screen:
	Release: 30-50 ms
	Debug: 60-100 ms

1/18/2024:
	OpaqueManager now works fully and the whole engine works again.
	A couple small syntax changes have been made to hopefully make the library easier to use.
	- SpriteManager now has a requestSprite function, which makes requesting sprites a bit clearner, as opposed to having to pass the z value twice in the parameter
	- RenderRequest has been created to make handling render requests easier. Passing in this struct means that it'll be easier to manage the number of parameters functions that render will need. RenderProgram is now the first variable in each request, while the sprite and rendering primitive are the 2nd and 3rd, with default values for both; this is because a RenderProgram is always needed but the latter two are optional

Though most of the engine has been streamlined, PolyRender remains a bit of an oddball. It uses BasicRenderPipeline, but still does most of the data storage and rendering by itself. This is due mainly to the fact that it handles verticies differently than most render pipelines. BasicRenderPipeline was done with the idea that verticies were the only data that would change per vertex, whereas everything else would change per rendering call. PolyRender is notably different, which requires its requests to be stored differently and its verticies to change per rendering call. For example, you can't just store one color for all 4 verticies of a render rect request, you have to give a color for each vertex. 

I am interested in fixing this issue but not only does it make making the requests harder, it also makes storing the data for the requests harder. Not sure how I'm gonna do it yet tbh. For now, the work around is to render polygons first.

1/12/2024:
	Massive changes. 
	First of all, say good by to RenderProgram. For its last month, RenderProgram was a slightly more specialized version of BasicRenderPipeline that could render sprites but that is no longer the case. SpriteManager now handles ALL rendering, sprites or not and the request function has been changed to match this. Requests now involve a Sprite pointer, which can be null. TransManager now implements this change, why OpaqueManager is still a WIP. Rendering is also now done from the SpriteManager as opposed to the actual pipelines (tho BasicRenderPipeline retains its draw function in case you need to draw something RIGHT NOW) so RenderProgram has nothing really to do. It does live on as a ghost as it is now an alias for BasicRenderPipeline because a lot code refers to RenderPrograms.f
	The reason for this was because if DEPTH_TEST was turned on, fragments from non-sprite render pipelines would eat underlying fragments even if they were transluscent. This could be worked around by simply turning DEPTH_TEST off and purely using TransManager to sort all fragments. At least in 2D, this works perfectly fine. OpaqueManager would have to be turned off but for most fragments aren't opaque anyway so it's not a huge performance drop. Still, I'm not sure I'm a huge fan of leaving DEPTH_TEST off forever. Leaving it off works for 2D but who knows maybe I'll go 3D someday. Besides, streamlining non-sprite and sprite rendering just makes sense and should've probably been done regardless of the DEPTH_TEST issue. If I'm going to streamline anyway, then why not keep OpaqueManager for a slight performance boost. 

12/18/2023:
	WTF it's been 9 months??
	BasicRenderPipeline and RenderProgram now no longer use initializing functions and instead have constructors. The reason this wasn't always the design was because I hated the syntax of creating a pointer to an uninitialized pipeline/program but honestly that's better design. Having a pointer means we have more control over when we get to initialize (lazy initializing) and gives us an easier way to make sure an important static member variable has been created (such as the main RenderProgram in a Game class).
	Speaking of, Renderprogram is now a child class of BasicRenderPipeline and honestly by this time next year, RenderProgram may cease to exist. After BasicRenderPipeline trivialized rendering things, RenderProgram is kind of a wrapper class. Right now, it has a single member variable, which is a BasicRenderPipeline, and then a bunch of functions that set uniforms. That's literally it. Functionality wise, RenderProgram renders sprites, so the verticies it passes in are different and it has to bind a texture before drawing. 

3/10/2023:
	RenderCamera's static camera has now been moved to ViewPort, as this makes more sense. ViewPort defines rendering to teh screen, it would make sense that it controls the one central camera. Similarly, ViewPort::update has now been updated to take in no parameters, instead using ViewPort's static camera. In case a program wants to use a child class of RenderCamera, ViewPort's static camera is still a pointer to RenderCamera, rather than an actual instance. 

1/29/2023:
	ViewPort has been changed to use UBOs (Uniform Buffer Objects) under the assumption that every shader that has a view and projection matrix will have the matrix linked to the same location. This is not an insane requirement and to be honest, I can't think of a single shader that will not use those two matrices. Whereas previously every shader set their own uniforms and used ViewPort::getOrtho(), they now instead all read the data from the same uniform buffer. ViewPort::getOrtho() is now only calculated once per frame as is the view matrix calculation, rather than once per RenderProgram per frame. This does mean that ALL shaders will use the same camera view. For things like UI, which are rendered in the same spot regardless of position, we'll probably have to define a shader which doesn't use the view matrix. Honestly doesn't sound like a big deal, and we could even specialize the shader for UI.
	There is an issue with RenderProgram and Sprite calling glDelete* after the GL Context has been destroyed. On one hand, it follows C++ principles to handle the destruction of all properties upon destruction of a class however, as far as I could tell there was no way to guarantee that glDelete* would only be called before the GL Context was destroyed. This is such a common problem that it has its own page on the OpenGL Wiki:
https://www.khronos.org/opengl/wiki/Common_Mistakes#The_Object_Oriented_Language_Problem.
The page also proposes an number of solutions. I tried creating a global GLContext class that handles creating and destroying the gl context. The issue is even with std::atexit, there is no way to guarantee that it will terminate if you close the app via the console window. That could be a dangerous way to close the app that we should not have to worry about though. In any case, I've found it easiest to jsut not have RenderProgram and Sprite free up resources. It's a bit unsafe but it also doesn't make sense for a Sprite to be deleted during the program's run time. The only way is if they go out of scope in a function.  

1/22/2023:
	SpriteManager now handles transluscent and non-transluscent (opaque) fragments, with the work being divided among two separate managers, OpaquesManager and TransManager. TransManager operates similarly to an older design for SpriteManager, where all sprite requests were sorted by z and then compiled and rendered. OpaquesManager still allocates a whole vector for each Sprite-RenderProgram and then renders each vector. 
	A new addition is a "spiritual successor" to SpriteParameter: FullPosition, which represents position, dimensions, and z of a request. These 3 fields are used by every request in some way; you have to know where to render something and how big it is. Z is a big less important but for transluscent fragments it is absolutely required for sorting, and so FullPosition was made to ensure that it would be easy to figure out the Z of each request. It might be more efficient to make FullPosition a parameter only for transluscent requests since not specifying a field and then instead filling a buffer with 0s is faster than specifying 0 and copying the 0 into the buffer, especially since that requires an additional recursive call. For now, both opaques and transluscents use FullPosition.

1/19/2023: 
	A lot of refactoring in Sprite and RenderProgram and how rendering works. Previously, Sprite and its descendants + RenderProgram were really bloated with a lot of functionality of which only a select few of which actually worked. Sprite held texture data, vertice data, had functions to load texture data into VBOs, and could draw itself. RenderProgram served as a rendering pipeline consisting of a vertex and fragment shader but also held information of the overall viewport, notably screen dimensions. Caught in the middle of this mess was Sprite's descendant classes, who were forced to use Sprite's convoluted structure, SpriteParameter which was a whopping 72 bytes for a long time, and SpriteManager, which was made to sort fragments by z coordinate to help with blending but ended up just reimplementing what SpriteWrapper did. Hilariously, SpriteWrapper ended up doing virtually nothing; its original purpose was to render all requests for a sprite at once but when it became apparent that when a sprite needs to be rendered is dependent on requests for other sprites, everything was sent to the SpriteManager. SpriteWrapper's remaining purpose was to load request data into a buffer and then render it, which Sprite could already do. This recent round of refactoring, which has now spanned about two weeks, (hopefully) fixes a lot of the issues with the old pipeline. 
	SpriteWrapper: REMOVED. As described previously, simply not needed anymore. 
	Sprite: REWORKED, to only hold texture data. As of this writing, Sprite still holds extraneous data like its own vertice data (which is the same among all sprites) but that will be changed in the final update. Effectively Sprites are just wrapper classes for OpenGL Textures at this point; they serve to provide the texture as well as basic information about the texture, notably its transluscency and its dimensions. 
	ViewPort: ADDED. No longer will RenderProgram be an almagamation of rendering pipelines and  and screen data. ViewPort now holds screen dimensions as well as ViewRanges that represent these dimensions.
	RenderProgram: REWORKED, drastically for that matter. The class now represents a rendering pipeline, nothing more. Perhaps more interesting is how data is passed to it. I experimented with 3 versions of passing data:
	new SpriteParameter solution, which moved some of the rendering work, to RenderProgram
	new bytes solution
	new sprite-renderprogram pair bytes solution

	The latter two are perhaps the most interesting. SpriteParameter and its descendants, AnimationParameter and FontParameter, seeked to pass a flexible data structure into the rendering pipeline. By flexible, I mean that I wanted my method of passing data to 1) be able to change the amount of data it passed without having to rewrite all my old code and 2) be able to pass different types of data in one pass, like glm::vec4 and float. SpriteParameter did this well, but whenever I wanted to pass new/additional data to the pipeline it required me to create a new struct as well as a new class to handle passing that additional data. Thanks to variadic parameters and some questionable reinterpret_casting, RenderProgram can now take infinite parameters of different types, convert them all into a series of bytes, and then pass into rendering pipeline. The difference between bytes solution and pair bytes is that bytes uses a red black tree (std::multiset) to sort requests by sprite to ensure they are all rendered in one batch. pair bytes instead uses a hash map (std::unordered_map) to directly map each sprite-renderprogram pairing into a vector, where the bytes are copied in. pair bytes is SIGNIFICANTLY faster than all other solutions, mainly because all the other solutions have significant overhead in that they have to sort the data and then compile the bytes into a data buffer when pair bytes directly uses the vector for rendering, no copying needed. The big downside is the size: allocating a whole std::vector for each sprite-renderprogram pairing might be costly given a large enough project. It also becomes significantly slower based on how much data is passed in, whereas SpriteParameter is more consistent, probably due to recursion. For now, the performance bump can't be denied and it's a solid general purpose rendering system.

	Rough Metrics for rendering 409600 spriteswith O3 optimizations and without SDL_GL_SwapWindow:
new SpriteParameter solution: ~120 - 150 ms per frame
new bytes solution: 	      ~180 - 200 ms per frame
new pair bytes solution:      ~40 - 80 ms per frame
	
	In addition, RenderProgram now also holds vertice data, and has its own transformation VBO and VAO. Vertice data VBO will most likely be moved into SpriteManager in the future, since the current vertice data is only for rendering simple sprites. For now, RenderPrograms initiate the vertice VBO upon initialization and bind them to the VAO. When rendering a sprite, the RenderProgram binds the sprite's texture to the VAO and buffer the sprites' request info into its own transformation VBO. These are very sprite specific qualities and may change in the future.	
	SpriteManager: REWORKED. SpriteManager currently takes opaque sprites (sprites that have alpha values of either 0 or 1, no transluscency) and compiles request data for each sprite-renderprogram pair into a vector unique to each pair. Upon rendering, it goes through each pair and loads the data stored in the vector into the corresponding program. Z sorting has not yet been implemented but the plan is to have separate systems for both, since opaques can be rendered in any order and before transluscents while transluscents have to be sroted by z. The goal is to have SpriteManager handle ALL sprites, irrelevant of sprite and render program, although it may be more efficient to have more generalized data structures. It will serve as a general purpose rendering system.
	BaseAnimation, Sprite9, Font: STATUS UNKNOWN. Sprite9 I have not touched in so long that I'll probably comment out until I next need it. Animations are part of the reason RenderPrograms were changed so much and will have a new RenderProgram that takes in time since start to calculate which frame to use on the GPU, which will hopefully be faster. Font is not too different from rendering sprites and will benefit greatly from how much easier it is to create new rendering pipelines now.
	Shaders: REWORKED, partially. Namely basicProgram, which used vertexShader and fragmentShader, will most likely have a new vertex shader from now on, currently known as "betterShader". betterShader does all our matrix math on the GPU, which requires significantly less data to be passed in and should be faster. 


11/30/2022: 
	Added floatEquals to vanilla.h. Basically a way to check if two floats are equal given a certain precision range. FLOAT_COMPARE is a macro that lets us do things like >= between floats without having to do (a > b) || (floatEquals(a,b). Basically it's shorthand. This can be used to make other parts of the resources library more accurate

11/21/2022:
	SUccessfully implemented separating axis theorem for collision between rotated rectangles. This nearly halved the run time per frame in SpatialHashGrid. The way it works is a little bit different from how SAT is explained online, but the general mathematical principles are the same. Instead of projecting the vertices onto each rectangles' axis, however, we instead transform one rectangle around the other, essentially converting the other rectangle back into a non-rotate rectangle. From there we compare their bounding boxes, to see if they interesect, then repeat with the other rectangle as the transformed one. If both bounding boxes intersect, we have a collision.

8/28/2022:
	ForcesComponent now adds forces once every millisecond, which is calculated using DeltaTime::deltaTime.
	MoveComponent now has a new parent class called BasicMoveComponent, which simply implements a moveVector that is added to the rect position. Sometimes, MoveComponent's target based movements are just not a good fit, so BasicMoveComponent will provide a much simpler interface.

08/25/2022:
	Added minor RenderCamera setters that allow the user to more easily modify the camera's position.

8/19/2022:
	Added a startingFrame variable to SpriteComponent that tracks when an animation started running; obviously useless if the sprite is an actual sprite and not a spritesheet, although I think that'll be rare. This variable works with the new BaseAnimation::getFrameIndex() function which returns the current frame that should be run given a startingFrame and the fps. It's a very simple function but is very useful for ensuring that each frame of an animation is run sequentially rather than leaving it to SDL_GetTicks().

8/12/2022:
	- Sequencer now instead of calling a Callable once a frame for a set duration, will now guarantee that a Callable will run its requested number of iterations (unless Callable's function returns true of course). This eliminates the need for a "timePassed" variable, and is instead replaced with "numOfReps" which represents the number of times we've called the Callable. This helps ensure that if the number of repetitions is higher than the time frame, that they will all be run and at a higher rate than before. Previously, a Callable would never be called more times than the time frame; at best it would called the same number of times, since a Callable could at most be called once per frame. Now, a Callable can be called an unlimited number of times a frame.


8/7/2022: 
	- Added TaskID, which allows SpatialGrid to update entities without updating them more than once
	- Fixed bug where SpatialGrid::Node wasn't hashing entities correctly. SpatialGrid::normalizeCoord is now available globally, allowing Node to use the function
	- RenderComponent no longer takes in a camera; it's easier just to use RenderCamera::currentCamera. If RenderComponents need different cameras in the future, just change the current camera. 
	- SpriteComponent no longer has a modified variable. Instead, sParam is set to defaultRender() immediately after rendering; if it's modified, it is rendered as modified. This is a much simpler solution that allows SpriteComponent to be easy to use while also allowing modifications that only last one frame.
	- RenderProgram now renders sprites in ascending z order again.

12/5/2019:
	RawQuadTree was changed from a quadtree of raw pointers to weak pointers before being changed back to raw pointers. The reason for changing to weak pointers was to prevent dangling pointers in the case of a master list deleting an object. However, there's no reason to use weak ptr because removal of the object from the master list also removes the pointer from the quadtree. The benefit of a weak_ptr is that it keeps track of whether or not 
the object still exists but in this case, it wouldn't matter since the pointer would be deleted anyway. The remove function from the quadtree already removes the pointers in the tree, so it makes no sense to have weak_ptr. 
	QuadTree's getNearest methods were changed to modify a vector of shared_ptr. This allows for std::shared_ptr or weak_ptr copying and allows other objects to share QuadTree's ownership.